<html><head><title>R: Hierarchical Clustering by Minimum (Energy) E-distance</title>
<link rel="stylesheet" type="text/css" href="../../R.css">
</head><body>

<table width="100%" summary="page for energy.hclust {energy}"><tr><td>energy.hclust {energy}</td><td align="right">R Documentation</td></tr></table>
<h2>Hierarchical Clustering by Minimum (Energy) E-distance</h2>


<h3>Description</h3>

<p>
Performs hierarchical clustering on a set of Euclidean distance 
dissimilarities by minimum (energy) E-distance method.
</p>


<h3>Usage</h3>

<pre>
    energy.hclust(dst)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>dst</code></td>
<td>
dissimilarity object produced by <code>dist</code> with
<code>method=euclidean</code>, or lower triangle of distance
matrix as vector in column order. If <code>dst</code> is a square
matrix, the lower triangle is interpreted as a vector of
distances.</td></tr>
</table>

<h3>Details</h3>

<p>
This function performs agglomerative hierarchical cluster analysis
based on the pairwise distances between sample elements in <code>dst</code>.
Initially, each of the n singletons is a cluster. At each of n-1 steps, the 
procedure merges the pair of clusters with minimum e-distance. 
The e-distance
between two clusters <i>C_i, C_j</i> of sizes <i>n_i, n_j</i> is given by
</p><p align="center"><i>e(C_i, C_j)=frac{n_i n_j}{n_i+n_j}[2M_{ij}-M_{ii}-M_{jj}],
</i></p><p>
where
</p><p align="center"><i>M_{ij} = 1/(n_i n_j) sum[1:n_i, 1:n_j] ||X_(ip) - X_(jq)||,</i></p><p>
<i>|| ||</i> denotes Euclidean norm, and <i>X_(ip)</i> denotes the p-th observation in the i-th cluster.  
</p>
<p>
The return value is an object of class <code>hclust</code>, so <code>hclust</code>
methods such as print or plot methods, <code>plclust</code>, and <code>cutree</code>
are available. See the documentation for <code>hclust</code>.
</p>
<p>
The e-distance measures both the heterogeneity between clusters and the
homogeneity within clusters. E-clustering is particularly effective in
high dimension, and is more effective than some standard hierarchical
methods when clusters have equal means (see example below).
For other advantages see the references.
</p>


<h3>Value</h3>

<p>
An object of class <code>hclust</code> which describes the tree produced by
the clustering process. The object is a list with components: 
</p>
<table summary="R argblock">
<tr valign="top"><td><code>merge:</code></td>
<td>
an n-1 by 2 matrix, where row i of <code>merge</code> describes the
merging of clusters at step i of the clustering. If an element j in the
row is negative, then observation -j was merged at this
stage. If j is positive then the merge was with the cluster
formed at the (earlier) stage j of the algorithm.</td></tr>
<tr valign="top"><td><code>height:</code></td>
<td>
the clustering height: a vector of n-1 non-decreasing
real numbers (the e-distance between merging clusters)</td></tr>
<tr valign="top"><td><code>order:</code></td>
<td>
a vector giving a permutation of the indices of 
original observations suitable for plotting, in the sense that a 
cluster plot using this ordering and matrix <code>merge</code> will not have 
crossings of the branches.</td></tr>
<tr valign="top"><td><code>labels:</code></td>
<td>
labels for each of the objects being clustered.</td></tr>
<tr valign="top"><td><code>call:</code></td>
<td>
the call which produced the result.</td></tr>
<tr valign="top"><td><code>method:</code></td>
<td>
the cluster method that has been used (e-distance).</td></tr>
<tr valign="top"><td><code>dist.method:</code></td>
<td>
the distance that has been used to create <code>dst</code>.</td></tr>
</table>

<h3>Author(s)</h3>

<p>
Maria Rizzo
</p>


<h3>References</h3>

<p>
Szekely, G. J. and Rizzo, M. L. (2003) Hierarchical Clustering
via Joint Between-Within Distances, submitted.
</p>
<p>
Szekely, G. J. and Rizzo, M. L. (2003) Testing for Equal
Distributions in High Dimension, submitted.
</p>
<p>
Szekely, G. J. (2000) <i>E</i>-statistics: Energy of
Statistical Samples, preprint.
</p>


<h3>See Also</h3>

<p>
<code><a href="edist.html">edist</a></code> <code><a href="ksample.e.html">ksample.e</a></code> <code>hclust</code>
</p>


<h3>Examples</h3>

<pre>
   ## Not run: 
   
   library(cluster)
   data(animals)
   plot(energy.hclust(dist(animals)))
   
## End(Not run)
   
   library(mva)
   data(USArrests)
   ecl &lt;- energy.hclust(dist(USArrests))
   print(ecl)    
   plot(ecl)
   cutree(ecl, k=3)
   cutree(ecl, h=150)
   
   ## compare performance of e-clustering, Ward's method, group average method
   ## when sampled populations have equal means: n=200, d=5, two groups
   z &lt;- rbind(matrix(rnorm(1000), nrow=200), matrix(rnorm(1000, 0, 5), nrow=200))
   g &lt;- c(rep(1, 200), rep(2, 200))
   d &lt;- dist(z)
   e &lt;- energy.hclust(d)
   a &lt;- hclust(d, method="average")
   w &lt;- hclust(d^2, method="ward")
   list("E" = table(cutree(e, k=2) == g), "Ward" = table(cutree(w, k=2) == g),
        "Avg" = table(cutree(a, k=2) == g))
 </pre>



<hr><div align="center"><a href="00Index.html">[Package Contents]</a></div>

</body></html>
